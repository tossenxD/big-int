\section{Division}
\label{sec:div}

The last of the basic arithmetics is division. It is far more complicated than
the others and intrinsically in conflict with our domain. We say the division is
\textit{exact} when the divisor precisely divides the dividend. When the
division is not exact, the result is ordinarily represented by a fraction -- yet
we do not desire to leave the domain of integers. Instead, we use the notion of
\textit{quotient} and \textit{remainder} commonly present in integer semantics:
\begin{align}
  u~\mathtt{quo}~v &\coloneq \lfloor u/v \rfloor\\
  u~ \mathtt{rem}~v &\coloneq u - \left( u~\mathtt{quo}~v \right)\cdot v
\end{align}
Usually, the quotient is associated with the division operator and the remainder
with the modulus operator. Our division computes both values and return them as
a pair.

A common way to reason about division is to multiply the dividend with the
inverse of the divisor, also called the reciprocal. GMP use reciprocals for
division by single precision, but since reciprocals are expensive to compute,
their basecase division use Knuth's algorithm for long division, also known as
\textit{grade-school} division \cite{GMP, knuth97}. This algorithm is inherently
sequential: It iteratively produce the result by finding one correct digit per
iteration, and thus, unfit for GPGPU. As a result, we focus on algorithms using
the inverse of the divisor.

A well known algorithm to find reciprocals is the Newton-Raphson method. It
takes an initial approximation, and through a series of iterative steps (also
called Newton iterations), refines the precision of the approximation. While it
too performs a number of inherently sequential iterations, the precision of the
approximation roughly doubles at each iteration, making it more suitable for
GPGPU than long division.

However, it presents a new hurdle w.r.t.\ the internal representation of both
the inverse and the intermediate approximations in iteration steps. One solution
is to use fractions internally and convert back to integers before returning the
output. The downsides to this solution is the potential loss of precision when
using floating points (i.e.\ it will no longer be an exact arithmetic) and the
overhead of converting between representations.

Instead, we use Watt's efficient and exact arithmetic algorithm for computing
quotients, presented in \cite{watt2023efficient}. The prerequisite of the
algorithm is the existence of a shift operation for the chosen data type -- which
is a very efficient operation for integers -- and a multiplication method given
as a argument. The intuition is to utilize the shift operation in order to avoid
the domain change associated with computing the inverse, by instead computing
what is referred to as the \textit{whole shifted inverse}.

This section is structured as follows: In \ref{subsec:divalg} we give a detailed
introduction to the algorithm formulated by Watt in \cite{watt2023efficient}. We
also present some revisions to the algorithm -- notably an unconsidered corner
case -- and reflect on its adaptability to the domain of big integers. In
\ref{subsec:divproto} we show a sequential prototype of the algorithm written in
C. It serves to fully understand the complexities involved in adapting the
algorithm to big integers. Lastly, in \ref{subsec:divfut} we demonstrate how to
parallelize the algorithm using Futhark, based on the methods we discovered
during the prototyping.

\subsection{Algorithm}
\label{subsec:divalg}

Before discussing the exact division algorithm, we introduce a new notation: The
\textit{precision} of a big integer (denoted by $p$) refers to the number of
digits without leading zeroes. E.g.\ the integer $\arr{1,2,0}$ has size $m=3$
and precision $p=2$.

We will now give the intuition behind the algorithm defined by Watt in his paper
\cite{watt2023efficient}, and refer to his paper for the proofs and the generic
version. The foundation of the algorithm is a whole shift operator and a whole
shifted inverse operator:

\begin{definition}[whole shift and whole shifted inverse of big integers]
  We define a $n \in \mathbb{Z}$ whole shift and $n' \in \mathbb{N}$ whole shifted inverse of big
  integers $u\in \mathbb{N}$ and $v\in \mathbb{N}^{+}$ in base $B$ as:
  \begin{equation}\label{eq:shifts}
    \mathtt{shift}_n~u \coloneq \lfloor u \cdot B^n \rfloor \quad \qquad \mathtt{shinv}_{n'}~v \coloneq \lfloor B^{n'}/ v \rfloor
    \end{equation}
\end{definition}

A shift in our array-oriented representation behaves similarly to a binary
system arithmetic shift, e.g.\ $\mathtt{shift}_1~\arr{1,2,3} = \arr{0,1,2}$ and
$\mathtt{shift}_{-1}~\arr{1,2,3} = \arr{2,3,0}$. The shifted inverse has a more
abstract interpretation -- given some $n'>p$ it essentially behaves as a
fractional inverse that is then "shifted into our domain". Consider the
following example:

Suppose we have the integer $u=\arr{1,2,3}$ in base $B=2^{32}$ and wish to divide
it by the integer $v=\arr{1,1,0}$ in base $B$. Since $v$ is of precision $p=2$,
we get a proper inverse representation of $v$ by computing the $n$ shifted
inverse for some $n>p$. We pick $n=3$ and get:
\begin{equation}
\label{eq:3}
\mathtt{shinv}_3~\arr{1,1,0} = \arr{0,4294967295,0}
\end{equation}
We can then multiply $u$ with the shifted inverse (expanding the result size),
and gets:
\begin{equation}
  \label{eq:4}
  \arr{1,2,3}\cdot\arr{0,4294967295,0} = \arr{0,4294967295,4294967294,4294967294,2}
\end{equation}
Now, since the fractional part of the inverse was "shifted into our domain" by
3, the result of this multiplication is also shifted by 3 (from associativity of
multiplication). Hence we shift it by $-3$ (and compress it to the original
size):
\begin{equation}
  \label{eq:5}
  \mathtt{shift}_{-3}~\arr{0,4294967295,4294967294,4294967294,2} = \arr{4294967294,2,0}
\end{equation}
The correct answer is $\arr{4294967295,2,0}$, so the method is off by $1$. This
is an accommodated byproduct of computing the whole shifted inverse. However,
the method approximates the result by at most $1$, allowing us to mechanically
adjust the result.

The formal definition given by Watt in Theorem 1 of his paper
\cite{watt2023efficient} is as follows:

\begin{definition}[quotient of big integers by whole shifted inverse]
  For the base $B$ big integers $u$ and $v$ and some $h\in \mathbb{N}$ s.t.\
  $u \leq B^h$, the quotient of $u$ by $v$ is:
  \begin{equation}
    \label{eq:defquo}
    u~\mathtt{quo}~v = \mathtt{shift}_{-h}~ (u \cdot \mathtt{shinv}_h~v) + \delta,\quad \text{where~} \delta \in \{0,1\}
  \end{equation}
\end{definition}

The challenge now lies in computing \texttt{shinv}. Watt's algorithm use a
Newton iteration over integers and specialized to the base in order to use
shifts rather than fractions. The algorithm can roughly be divided into three
steps:
\begin{enumerate}[label=\Roman*]
\item Handle the special (and easy) cases, namely when $v \leq B$ or $v > B^h/2$.\label{shinvI}
\item Find an initial approximation that guarantees the Newton iterations
  converges fast.\label{shinvII}
\item Refine the initial approximation iteratively until it is sufficient.\label{shinvIII}
\end{enumerate}
Listing \ref{shinv} below shows the pseudocode for this operation. In step
\ref{shinvI} we have four special cases. They serves dual purposes: To guarentee
that $B < v \leq B^h/2$ and being faster. The first case says that if $v$ only
consists of a single digit, then we can use a division by single precision
method instead.\footnote{As mentioned earlier in how GMP handle division, this
  case can generally be handled more efficient.} The next two cases is if
$v > u$ or $2v > u$ and so the quotient is $0$ and $1$, respectively. The last
case is when $v$ is exactly a power of its base, and we can use the rule
$x^a/x^b=x^{a-b}$ instead. However, this is where we introduce our revisions, because the refinement methods use ...


\begin{lstlisting}[language=pseudo,escapeinside={!}{!},caption={\footnotesize Pseudocode for computing \texttt{shinv}$_h~v$ in base $B$, where $B^k \leq v < B^{k+1}$, \texttt{quo}$_{\mathtt{digit}}$ and \texttt{*}$_{\mathtt{digit}}$ are quotetion and multiplication by single precision, respectively, and \texttt{REFINE} is some refinement method.},label={shinv}]
fun SHINV h k v =
  -- 1. Special cases (!{\hypersetup{allcolors=ForestGreen}\ref{shinvI}}!)
  if v          <  B!$^{\phantom{\texttt{h}}}$! then return B!$^\mathtt{h}$! quo!$_{\texttt{digit}}$! v[0]
  if v          >  B!$^\texttt{h}$! then return 0
  if (v *!$_{\texttt{digit}}$! 2) >  B!$^\texttt{h}$! then return 1
  if v          == B!$^\mathtt{k}$! then return B!$^{\texttt{h}-\texttt{k}}$!
  -- 2. Initial approximation (!{\hypersetup{allcolors=ForestGreen}\ref{shinvII}}!)
  V = v[k-2] + (v[k-1] * B) + (v[k] * B!$^{\texttt{2}}$!)
  w = (B!$^{\texttt{4}}$! - V) / V + 1
  -- 3. Refine until sufficient (!{\hypersetup{allcolors=ForestGreen}\ref{shinvIII}}!)
  if h - k <= 2 then return shift (h - k - 2) w 
  return REFINE v w h k 2
\end{lstlisting}





\begin{figure}
{
\hrule\vspace*{-0.4ex}
\begin{minipage}{.45\textwidth}
\begin{lstlisting}[language=pseudo,frame=,escapeinside={!}{!}]
-- finds `k` s.t. !$\green \texttt{B}^{\texttt{k}} \leq \texttt{v} < \texttt{B}^{\texttt{k}+\texttt{1}}$!
fun FINDK v =
  k = (sizeof v) - 1
  while v[k] == 0 do
    k -= 1
  return k

-- finds `p` s.t. !$\green \texttt{v} < \texttt{B}^{\texttt{p}}$!
fun PREC v =
  return FUNDK v + 1
\end{lstlisting}
\end{minipage}\hfill
\begin{minipage}{.45\textwidth}
\begin{lstlisting}[language=pseudo,firstnumber=11,frame=,escapeinside={!}{!}]
-- finds `h` s.t. !$\green \texttt{u} \leq \texttt{B}^{\texttt{h}}$!
fun FINDH u =
  h = FINDK u
  if u[h] == 1
  then return u
  else return u + 1

-- computes !$\green ( \texttt{v}\cdot \texttt{w})~\texttt{rem}~\texttt{B}^{\texttt{L}}$!
fun MULMOD v w L =
  return MUL (take L v) (take L w)
\end{lstlisting}
\end{minipage}\vspace*{-0.8ex}
\hrule
}
\caption{\footnotesize Helpers for Watt's division algorithm, where MUL is some given multiplication method.}
\label{divhelpers}
\end{figure}


The term $B^h-v \cdot w$ appears in each iteration step. While it can be computed
straightforward, Watt increases the efficiency by using close products. The idea
is that in cases where the product $v\cdot w$ is close to $B^h$ by a factor of
$|B^h- v\cdot w|\leq B^L, L < h$, only the lower $L$ digits of the product is
needed. Hence, we can use a truncated multiplication of size $L$ rather than the
size of $v$ and $w$. Listing \ref{powdiff} shows the pseudocode for this
computation:
\begin{lstlisting}[language=pseudo,escapeinside={!}{!},caption={\footnotesize Pseudocode computing $B^{h}- v \cdot w$ efficiently using close products and helpers from Listing \ref{divhelpers}, where $l$ is number of correct digits in $w$, \texttt{SUB} is big int subtraction, \texttt{false} is unsigned, and \texttt{true} is signed.},label={powdiff}]
fun POWDIFF v w h l =
  L = (PREC v) + (PREC w) - l + 1
  -- Constant case where !$\green\texttt{v}\cdot \texttt{w} = \texttt{0}$!, so result is B!$^{\green\texttt{h}}$!
  if (v == 0) || (w == 0) then return (B!$^{\texttt{h}}$!, false)
  -- Worst case where the multiplication !$\green\texttt{v}\cdot \texttt{w}$! is in full size
  if L >= h               then return SUB B!$^{\texttt{h}}$! (MUL v w)
  -- Close product case where only the lower L digits of !$\green\texttt{v}\cdot \texttt{w}$! is needed
  P = MULMOD v w L
  if P      == 0 then return (P, false)
  if P[L-1] == 0 then return (P, true)
  return SUB B!$^{\texttt{L}}$! P
\end{lstlisting}


REMAINING:
\begin{lstlisting}[language=pseudo,escapeinside={!}{!},]
-- l is the number of leading correct digits
fun REFINE v w h k l =
  g = 2
  w = shift g w
  while h - k > l do
    m = min l (h - k + 1 - l)
    s = max 0 (k - 2*l + 1 - g)
    w = shift (-1) (STEP (k + l + m - s + g) (shift (-s) v) w m l g)
    l += m - 1
  return shift (-g) w

-- l is the number of correct digits and m the additional digits needed
fun STEP h v w m l g =
  -- 1. Compute !$\green \texttt{B}^{\texttt{h}}- \texttt{v} \cdot \texttt{w}$!
  (pwd, sign) = POWDIFF v w (h-m) (l-g)
  -- 2. Compute and return !$\green\texttt{w}+ \lfloor \texttt{w} \cdot ( \texttt{B}^{\texttt{h}}- \texttt{v}\cdot \texttt{w})\cdot \texttt{B}^{\texttt{-h}}\rfloor$!
  if sign
  then return SUB!$_{\texttt{abs}}$! (shift m w) (shift (2*m - h) (MUL w pwd))
  else return ADD!$_{\phantom{\texttt{abs}}}$! (shift m w) (shift (2*m - h) (MUL w pwd))

fun DIV u v =
  -- 1. Find assumptions
  h = FINDH u
  k = FINDK v
  -- 2. Avoid non-terminating loop
  if k == 1 then u = shift 1 u
                 v = shift 1 v
                 h += 1
                 k += 1
  -- 3. Find quotient and remainder
  q = shift (-h) (MUL u (SHINV h k v))
  r = SUB!$_{\texttt{abs}}$! u (MUL q v)
  -- 4. Find !\green$\delta$!
  if (r >= v) then q += 1
                   r -= v
  return (q, r)
\end{lstlisting}


\subsection{Prototype}
\label{subsec:divproto}
{\red [TODO; rewrite]}

We started by writing a prototype of the algorithm in C to better understand the
inner workings of the algorithm. In its creation, we discovered some
optimization with respect to our big integer data structure. Here are some
notable subroutines and how we handle them.

\begin{itemize}[leftmargin=*]
\item \textbf{Base Powers}\\
  These are prominent throughout the algorithm, and comes in a multitude of
  usecases. However, most of the time they express something structural about a
  big integer, and hence, can be optimized to a constant work check on the
  integer.

  E.g. consider the comparison $v > B^h$ for a big integer $v$ of precision $m$
  in base $B$. Instead of constructing $B^h$ and compare it to $v$, we can
  simply check whether any digits are index greater than $h$ are non-zero, the
  digit exactly at index $h$ is greater than $1$, or simply shortcircuit if
  $m < d$.
\item \textbf{Multmod}\\
  For big integers $u$ and $v$ in base $B$, we define
  $\fun{MultMod}(u,v,d) = (u \cdot v) \% (B^d)$. At first glance, this function
  requires to double the precision $m$ for the multiplication, and then run a
  computationally heavy modulus operation. However, taking the modulus of $B^d$
  corresponds to zeroing out the $m \log B - d$ upper bits of an integer.

  Thus, as these bits will not contribute to the result, $\fun{MultMod}$ is
  equivalent to a truncated multiplication. I.e. exact precision multiplication
  of precision $\fun{min}(d, m)$.

\item \textbf{Initial Approximation}\\
  The initial approximation is 4 digits divided by 2 digits and can be computed
  efficiently using register arithmetics, if we have access to registers of
  4$\times$ base size.

\item \textbf{PowDiff}\\
  This function computes the power difference of two big integers, their base
  and an exponent, defined $\fun{PowDiff}(u, v, h) = B^h - u \cdot v$. This function
  requires sign extension. However, instead of modifying our domain to signed
  big integers, we can simply return a boolean sign indicator - the sign will
  only dictate whether we add or subtract in the $\fun{Step}$-function, but the
  result will be unsigned regardless.

\item \textbf{Approximation Factor}\\
  Since the algorithm approximates the exact result by a factor of 1, i.e.
  $\delta = \{0,1\}$. We were not able to predict $\delta$, but it is trivially decidable
  by reversing the division with multiplication. This requires one extra
  multiplication, but is essentially free if we consider the remainder to be
  part of the algorithms output.
\end{itemize}

% \subsection{Single Precision Divisor}
% % In the prototype, a standard Long Division algorithm is used. Another way to
% % express the computation of long division is:
% % \begin{equation}
% %   \label{eq:1}
% %   q_i = \dfrac{\sum_{j=i}^{m-1} u_j \cdot B^{j-i}}{v}\% B
% % \end{equation}
% % E.g. consider the decimal number 500 divided by 4: We have
% % $q_0 = (500 / 4) \% 10 = 5$, $q_1 = (50 / 4) \% 10 = 2$ and
% % $q_2 = (5 / 4) \% 10 = 1$, i.e., the number 125.

% % We have the following rule for division and modulus:
% % \begin{equation}
% % \label{eq:2}
% % \frac{a}{b} \% c = () \% c
% % \end{equation}
% % \begin{equation}
% %   \label{eq:1}
% %   q_i = \dfrac{\sum_{j=i}^{m-1} \left( (u_j \% v)\cdot B^{j-i}\right) }{v}\% B
% % \end{equation}
% % \begin{equation}
% %   \label{eq:1}
% %   r_i = \left( \sum_{j=i}^{m-1} u_j \cdot B^{j-i} \right) \% v
% % \end{equation}

% % ~

% The quotient of size $m$ big integer $u$ and digit $d$ in base $B$ can be
% computed as:
% \begin{equation}
%   \label{eq:1}
%   q_i = \dfrac{\sum_{j=i}^{m-1} u_j \cdot B^{j-i}}{d}\% B
% \end{equation}
% E.g. consider the decimal number 500 divided by 4: We have
% $q_0 = (500 / 4) \% 10 = 5$, $q_1 = (50 / 4) \% 10 = 2$ and
% $q_2 = (5 / 4) \% 10 = 1$, i.e., the number 125. This approach does not fit a
% wordsize, as it includes the big integer $u$.

% In the sequential prototype, a standard Long Division algorithm is
% used\footnote{Since the divisor is single precision, it is called Short Division
%   instead of Long Division.}. The algorithm computes the partial quotient
% $q_{i\in\{0,..,m-1\}}$, using the partial remainder $r_{i\in\{0,..,m\}}$ as follows:
% \begin{equation}
%   \label{eq:1}
%   q_i = \left( r_{i+1} \cdot B + u_i\right) / d
% \end{equation}
% \begin{equation}
%   \label{eq:1}
%   r_i = \begin{cases} \left( r_{i+1} \cdot B + u_i\right) \% d & \text{if}~i<m \\ 0 & \text{otherwise} \end{cases}
% \end{equation}
% The intermideate results fits in a double word, and the algorithm is inherently
% sequential from left-to-right.

% From the definition of modulo, $a \% b = a - \lfloor \frac{a}{c} \rfloor \cdot b$,

\subsection{Futhark Implementation}
\label{subsec:divfut}

{\red [Missing]}




% As an example, lets handrun divison $\frac{u}{v}$ on the big integers $u = \texttt{[8,0,0,5]}$ and $v = \texttt{[4,2,0,0]}$ in base $B=2^{32}$. First, we must find $h$ such that $u\leq B^h$. A trivial pick is the precision of $u$ since the most significant digit is non-zero, i.e., $h=4$. Now comes the tricky part; we must find the whole shifted inverse of $v$ with respect to $h$, i.e., $\mathtt{shinv}_hv$.

% First we must find $k$ such that $B^k\leq v < B^{k+1}$. This is simply the precision - 1, so we have $k = 1$. Next we have the four special cases which guarantee that $B < v \leq \frac{B^h}{2}$. The first case is if $v < B$, or, if only the first digit of $v$ is set. The second case is if $v > B^h$, which means that $v>u$ and the division $\frac{u}{v}$ floors to $0$. The third case is if $2v > B^h$, which means that the division floors to $1$. The last case is if $v = B^k$, which means that $v$ is exactly a multiple of the base, and so the whole shifted inverse of $v$ is also a multiple of the base.

% In our example, we hit none of these special cases. Thus, we continue to compute a initial approximation of the whole shifted inverse. This approximation is computed by a division of a 4-digit big integer by a 2-digit big integer. Since we use base $B = 2^{32}$, we could do this in as one division in base $2^{128}$. However we chose to implement it, we get:
% \[l = \mathtt{min}(k,2) = \mathtt{min}(1,2) = 1\]
% \[V = \sum_{i=0}^lv_{k-l+i}B^i = 4 * B^0 + 2 * B^{1} = 8589934596\]
% \[w = (B^{2l}- V ) / (V + 1) = 18446744065119617020 / 8589934597 = 2147483645\]
% Hence, the initial approximation is the big integer $w = \mathtt{[2147483645,0,0,0]}$.

% We then check if this approximation is sufficient by the condition $h-k \leq l$, or in our case, $3 \leq 1$, which is clearly false. Since it is not a sufficient, we start refining. Let us consider \texttt{refine3} as the refine method, since this is the best proposed method.

% In this method, we have 2 guard digits, i.e:
% \[g = 2\]
% \[w = \mathtt{shift}_2w = \mathtt{[0,0,2147483645,0]}\]
% We then start the iterative refinement. This lasts until the sufficiency-condition above becomes true. We can see $l$ as the number of digits that are correctly approximated and $h - k$ as the total number of digits to approximate. In each iteration, we first find how much to grow $w$ denoted $n$ and how to scale $w$ in the iteration denoted $s$. In our case, we have:
% \[n = \mathtt{min}(h-k+1, l) = \mathtt{min}(2, 1) = 1\]
% \[s = \mathtt{max}(0, k - 2l + 1 - g) = \mathtt{max}(0,-2) = 0\]
% Now comes the meat of the iterations; we take a refinement \texttt{step}:
% \[ \mathtt{step}(k + l + n - s + g, \mathtt{shift}_{-s}v, w, n, l, g) = \mathtt{step}(3, 0, w, n, l, g)\]
% First we shift $w$ by the growth factor:
% \[w0 = \mathtt{shift}_nw = \mathtt{shift}_1 \mathtt{[0,0,2147483645,0]}= \mathtt{[0,0,0,2147483645]}\]

% Next up we compute the \texttt{powdiff} of $w$.
% \[w1 = \mathtt{powdiff}(v,w,h-n,l-g) = \mathtt{powdiff}(0,w,2,-1)\]
% This function computes $B^{h}-v\cdot w = B^{2}-0\cdot w = B^2$, but let us see how. First we find the difference between the number of approximated digits minus the guard digits and the precision after the multiplication plus 1:
% \[ L = \mathtt{prec}~v + \mathtt{prec}~w - l + 1 = 0 + 2 + 1 + 1 = 4\]
% Then, we check whether we can easily compute this, which we can if $w = 0 \lor v = 0 \lor L \geq h$, which is the case right now since $v = 0$ and also $L = 4 \geq 2 = h$. Hence, we return $B^{h}=B^{2}=18446744073709551616$.

% Now when we have the \texttt{powdiff}, we get our $w1$, which we then multiply by $w$:
% \[w1 = \mathtt{powdiff}(v,w,h-n,l-g) = 18446744073709551616\]
% \[w2 = w \times w1 = 730750817644604358339027025968017687532661637120\]
% As a big integer, we get $w2 = \mathtt{[0,0,0,0,2147483645]}$, which we now shift by $2n - h$:
% \[w3 = \mathtt{shift}_{2n - h}w2 = \mathtt{shift}_{2 - 3}w2 = \mathtt{shift}_{-1}w2 = \mathtt{[0,0,0,2147483645]}\]
% Lastly, we add $w3$ and $w0$, and so we get:
% \[ w0 + w2 =  \mathtt{[0,0,0,2147483645]} + \mathtt{[0,0,0,2147483645]} = \mathtt{[0,0,0,4294967290]}\]
% Now that we have the result of \texttt{step}, we shift it by $-1$:
% \[w = \mathtt{shift}_{-1} \mathtt{[0,0,0,4294967290]} = \mathtt{[0,0,4294967290]}\]
% Then we update the number of digits taken into account in the approximation by:
% \[l = l + n - 1 = 1 + 1 - 1 = 1\]

%%% Local Variables:
%%% mode: LaTeX
%%% TeX-master: "../main"
%%% End:
