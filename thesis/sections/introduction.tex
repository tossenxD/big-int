\section{Introduction}
\label{sec:intro}

Integers are commonly represented as either 32- or 64-bit in both hardware and
software. They are an essential part of computing and we expect most programs to
utilize integer arithmetics in accomplishing of a diverse range of
tasks. However, some applications require numbers that are too big to fit a
64-bit integer. One solution is resorting to floating-point arithmetics, but
those are both imprecise and inefficient compared to integer arithmetics.

Exact arithmetics with big integers (also called multiple precision integers or
big numbers) is the very foundation of numerous fields in computer science,
other formal sciences, natural sciences, and industry. Evident examples includes
cryptography and algebra. Big integers can span hundreds, thousands, or even
millions of bits, necessitating the exact arithmetics to be efficient in the
size of the integers. A widespread implementation for such arithmetics is the
GNU Multiple Precision Arithmetic Library (GMP) written in C and assembly
\cite{GMP}. One approach to further accelerate the performance is utilizing
massively parallel hardware such as General Purpose Graphics Processing Units
(GPGPUs).

In order to efficiently use GPGPUs, the underlying algorithms have to be adapted
and parallelized. Addition has shown to be very efficient, running in sub-linear
time \cite{DPPproject,blellochaddscan}. Multiplication classically runs in
quadratic time. {\red [Missing]}

% Researchers have found different efficient algorithms (and CUDA implementations
% thereof) for data parallel big integer arithmetic on the GPU, such as the
% convolution and the Fast Fourier Transform algorithm to perform efficient
% multiplication \cite{doi:10.1177/10943420221077964} \cite{Emmart2010HighPI}
% \cite{Bantikyan2014BigIM}.

Division is the hardest of the basic arithmetics. It traditionally involves a
long division algorithm that iteratively finds one correct digit
\cite{knuth97}. With the number of iterations linear in the input size, this
algorithm is a poor fit for GPGPU. Another common division approach is by
multiplicative inverses. Watt has shown an algorithm to efficiently compute
exact division by finding such an inverse, without leaving the original domain
\cite{watt2023efficient}. Its complexity mirrors that of its multiplication
method, which can be parameterized, and the number of iterations is logarithmic
in the input size, yielding a more GPGPU suitable algorithm.
\newline

This Thesis focus on efficient parallel implementations of exact big integer
arithmetics for GPGPU. We present the algorithms for sub-linear addition,
classical multiplication, and Watt's division by whole shifted inverse. We keep
algorithmic and parallelization efforts general, but narrow our implementations
to the Compute Unified Device Architecture (CUDA) platform through the
programming languages Futhark and C++. Both are high-level languages, but
operates vastly different. C++ allows low-level command of primitives and
fine-grained memory control, while interfacing directly with the CUDA runtime
API to produce GPGPU runable code \cite{cudaguide}. Futhark is a functional
array programming language that is designed around parallel basic blocks, making
programs more elegant and less dependant on hardware specifications in exhange
for loosing some of the fine-grained control
\cite{Henriksen:2017:FPF:3062341.3062354}.

{\red [Rewrite below]}

we will examine how to efficiently do arithmetic on big
integers using data parallel techniques on the GPU. We will specifically focus
on addition and multiplication, as these are the most basic operations. If time
permits, we will extend the scope to cover other arithmetic operations, such as
division \cite{watt2023efficient}. We aim to write a big integer library for
Futhark that abstract away the inner workings and complications of the big
integer implementation, such that these integers can be used as any other
integer data type without the imposed limitations.

In order to measure efficiency, we will also write a low-level CUDA
implementation to work as a foundation of comparison. By this comparison, we
should be able to determine the overhead of lifting from a low-level
hardware-dependent (CUDA) implementation to a high-level hardware-independent
(Futhark) implementation, and from there, should be able to optimize our
library further. Moreover, we will compare these implementations to the
state-of-the-art parallel big integer arithmetic CUDA library CGBN \cite{CGBN}.

\paragraph{Learning objectives}
\begin{itemize}
  \item To conduct literature search into algorithms for big integer arithmetic
    and survey the advantages and disadvantages of different approaches.
  \item To design a big integer representation that works well for both a
    low-level (CUDA) and high-level (Futhark) data parallel programming
    languages.
  \item To implement a big integer library in Futhark that supports addition
    and multiplication.
  \item To implement a big integer data type in CUDA that supports addition and
    multiplication.
  \item To analyze and evaluate implementations in terms of efficiency metrics
    such as speed.
  \end{itemize}

% Lastly, the files \texttt{div.c} and \texttt{div.fut} contains implementations
% of exact big integer division by whole shifted inverse. The C implementation is
% a sequential adaptation of the algorithm proposed by Watt in
% \cite{watt2023efficient}, wherefrom we parallelize in the Futhark
% implementation. These are not performance-optimized in the same manner as
% addition and multiplication, but moreso serves as a proof of concept of a
% parallel implementation of the algorithm. During the development we found some
% valuable insight, notably a corner case unconsidered in the original formulation
% of the algorithm. Hence, we also present a revised algorithm specialized for big
% integers and parallel execution.

%%% Local Variables:
%%% mode: LaTeX
%%% TeX-master: "../main"
%%% End:
