\section{Addition}
\label{sec:add}

Addition is the simplest of the basic arithmetic operators. It is a cornerstone
of arithmetics that can be used to define all other operations - an essential
part of a big integer library.

Former work has been carried out by students as part of a parallel course
project, which will serve as a stepping stone for the algorithm and
implementation of our addition \cite{DPP-project}.

This section is as follows: In subsection \ref{subsec:addalg} we present an
algorithm to compute big integer addition in parallel. In subsection
\ref{subsec:addcud} we discuss how to efficiently implement the algorithm on a
GPU in CUDA, and in subsection \ref{subsec:addfut} how to translate this
implementation to Futhark.

\subsection{Algorithm}
\label{subsec:addalg}

The additions of two big integers is the sum of the addition of their digits:
\begin{equation}
  \label{eq:add}
  u + v = \sum_{i=0}^{m-1}u_i\cdot B^{i} + \sum_{i=0}^{m-1}v_i\cdot B^{i} = \sum_{i=0}^{m-1}(u_i+v_i)\cdot B^{i}
\end{equation}

I.e. we can compute each digit of the result simply by adding the corresponding
two input digits. However, these additions may overflow the base size, which
results in a carry being added to the following digit. In turn, this digit may
now overflow, and so we need to add yet another carry, and so on. E.g. consider
the addition $199 + 1$ in decimal base; first we add $1$ to $9$ giving $0$ and a
carry, then we add $0$ and the carry to $9$ giving $0$ and another carry, which
we then add to $1$, resulting in the number $200$.

A sequential algorithm and illustration thereof is given in Figure
\ref{fig:addseq}. It is immidiate from the figure that the additions of digits
can be independently computed, and thus, trivially parallelizable. However, the
carries are dependent on all additions and carries before it.

\begin{figure}
  \centering
  \begin{minipage}{0.45\textwidth}
    \small
    \texttt{Input:} $u$ and $v$ of size $m$ base $B$\\
    \texttt{Output:} $w$ of size $m$ in base $B$
\begin{lstlisting}[language=pseudo,frame=]
c = 0
for i in (0..m-1)
    w[i] = u[i] + v[i] + c
    c = if overflow then 1 else 0
\end{lstlisting}
  \end{minipage}
  \begin{minipage}{0.45\textwidth}
    \centering
    \footnotesize
    \begin{tabular}{c}
      \begin{tabular}{|C{0.7cm}|C{0.7cm}|C{0.7cm}|C{0.7cm}|C{0.7cm}|}
        \hline
        $u_0$ & $u_1$ & $u_2$ & $\cdots$ & $u_{m-1}$\\ 
        \hline
      \end{tabular}\\
      \begin{tabular}{C{0.7cm}C{0.7cm}C{0.7cm}C{0.7cm}C{0.7cm}}
        $+$ & $+$ & $+$ & & $+$\\ 
      \end{tabular}\\
      \begin{tabular}{|C{0.7cm}|C{0.7cm}|C{0.7cm}|C{0.7cm}|C{0.7cm}|}
        \hline
        $v_0$ & $v_1$ & $v_2$ & $\cdots$ & $v_{m-1}$\\
        \hline
      \end{tabular}\\
      \begin{tabular}{C{0.7cm}C{0.7cm}C{0.7cm}C{0.7cm}C{0.7cm}}
        $+$ & $+$ & $+$ &  & $+$\\
      \end{tabular}\\
      \begin{tabular}{C{0.7cm}C{0.7cm}C{0.7cm}C{0.7cm}C{0.7cm}}
        $0$ & $c_1$ &  $c_2$ & $\cdots$ &$c_{m-1}$ \\
      \end{tabular}\\[-0.8ex]
      \begin{tabular}{C{0.15cm}C{0.15cm}C{0.15cm}C{0.15cm}C{0.15cm}C{0.15cm}C{0.15cm}}
       \diagonalarrow{} & & \diagonalarrow{} &  & \diagonalarrow{} &  & \diagonalarrow{}\\
      \end{tabular}\\[-2ex]
      \begin{tabular}{C{0.7cm}C{0.7cm}C{0.8cm}C{0.7cm}C{0.7cm}}
        $=$ & $=$ & $=$ &  & $=$  
      \end{tabular}\\
      \begin{tabular}{|C{0.7cm}|C{0.7cm}|C{0.7cm}|C{0.7cm}|C{0.7cm}|}
        \hline
        $w_{0}$ & $w_1$ & $w_2$ & $\cdots$ & $w_{m-1}$\\
        \hline
      \end{tabular}
    \end{tabular}
  \end{minipage}
  \caption{Pseudo-code and illustration of sequential addition algorithm.}
  \label{fig:addseq}
\end{figure}

Each addition may overflow at most once, and so we need to figure out when this
happens. In the former work by Olesen, Topalovic and Restelli-Nielsen, they
found that this happens when I) the addition already overflowed, or II) it
results in the maximum representable integer and the addition just before it
overflowed \cite{DPP-PROJECT}. This can be efficiently computed in parallel as a
prefix sum, specifically an exclusive one\footnote{Easy to see on the arrows of
  the illustration of the sequential algorithm in Figure \ref{fig:addseq}.}.

Thus, big integer addition parallelizes to a \fun{map}-\fun{scan} function
composition. Figure \ref{fig:addpar} lists and illustrates a generalized
parallel addition algorithm. The algorithm works in three steps: First, it
computes the result of the additions (\texttt{r}) and the augmented carries
(\texttt{a}) by mapping operator $\oplus$. Second, it computes a prefix sum
(\texttt{c}) over the augmented carries using operator $\otimes$ with left-associative
neutral element \texttt{e}. Third, it extracts the carries from the prefix sum
(using \texttt{f}) and adds them to the result of the additions over a map.

\begin{figure}
  \centering
  \begin{minipage}{0.47\textwidth}
    \footnotesize
    \texttt{Input:} $u$ and $v$ of size $m$ base $B$\\
    \texttt{Output:} $w$ of size $m$ in base $B$\\
    \texttt{Uses:} $f$ to extract carry from augmented carry
\begin{lstlisting}[language=pseudo,frame=,escapeinside={(*}{*)},name=paradd,backgroundcolor=\color{lightgray},]
(r, a) = map2 (*$\oplus$*) u v
\end{lstlisting}
\vspace{-\baselineskip}
\begin{lstlisting}[language=pseudo,frame=,escapeinside={(*}{*)},name=paradd,backgroundcolor=\color{Beige}]
c = scan_exc (*$\otimes$*) e a
\end{lstlisting}
\vspace{-\baselineskip}
\begin{lstlisting}[language=pseudo,frame=,escapeinside={(*}{*)},name=paradd,backgroundcolor=\color{LightSteelBlue}]
w = map2 ((*$\lambda$*) x y (*$\rightarrow$*) x + f y) r c
\end{lstlisting}
\end{minipage}
  \noindent\fcolorbox{white}{lightgray}{%
  \begin{minipage}{0.47\textwidth}
    \centering
    \footnotesize
    \begin{tabular}{c}
      \begin{tabular}{|C{0.7cm}|C{0.7cm}|C{0.7cm}|C{0.7cm}|C{0.7cm}|}
        \hline
        $u_0$ & $u_1$ & $u_2$ & $\cdots$ & $u_{m-1}$\\ 
        \hline
      \end{tabular}\\
      \begin{tabular}{C{0.7cm}C{0.7cm}C{0.7cm}C{0.7cm}C{0.7cm}}
        $\oplus$ & $\oplus$ & $\oplus$ & & $\oplus$\\ 
      \end{tabular}\\
      \begin{tabular}{|C{0.7cm}|C{0.7cm}|C{0.7cm}|C{0.7cm}|C{0.7cm}|}
        \hline
        $v_0$ & $v_1$ & $v_2$ & $\cdots$ & $v_{m-1}$\\
        \hline
      \end{tabular}\\
      \begin{tabular}{C{0.7cm}C{0.7cm}C{0.8cm}C{0.7cm}C{0.7cm}}
        $=$ & $=$ & $=$ &  & $=$  
      \end{tabular}\\
      \begin{tabular}{|C{0.7cm}|C{0.7cm}|C{0.7cm}|C{0.7cm}|C{0.7cm}|}
        \hline
        $r_{0}$ & $r_1$ & $r_2$ & $\cdots$ & $r_{m-1}$\\
        \hline
      \end{tabular}\\
      \begin{tabular}{C{0.15cm}C{0.15cm}C{0.15cm}C{0.15cm}C{0.15cm}C{0.15cm}C{0.15cm}}
        & &  &  &  &  & \\
      \end{tabular}\\[-2ex]
      \begin{tabular}{|C{0.7cm}|C{0.7cm}|C{0.7cm}|C{0.7cm}|C{0.7cm}|}
        \hline
        $a_{0}$ & $a_1$ & $a_2$ & $\cdots$ & $a_{m-1}$\\
        \hline
      \end{tabular}\\
    \end{tabular}
  \end{minipage}
  }\\
  \noindent\fcolorbox{white}{Beige}{%
    \begin{minipage}{0.4525\textwidth}
    \centering
    \scriptsize
    \begin{tabular}{c}
      \begin{tabular}{|C{0.7cm}|C{0.7cm}|C{0.7cm}|C{0.7cm}|C{0.7cm}|}
        \hline
        $a_{0}$ & $a_1$ & $a_2$ & $\cdots$ & $a_{m-1}$\\
        \hline
      \end{tabular}\\
      \begin{tabular}{C{0.15cm}C{0.15cm}C{0.15cm}C{0.15cm}C{0.15cm}C{0.15cm}C{0.15cm}C{0.15cm}C{0.15cm}C{0.15cm}C{0.15cm}}
        \texttt{e}$\shortrightarrow$ & $\otimes$ & $\shortrightarrow$ & $\otimes$ & $\shortrightarrow$ & $\otimes$ & $\shortrightarrow$ & $\otimes$ & $\shortrightarrow$ & $\otimes$ & \\
      \end{tabular}\\[-1.2ex]
      \begin{tabular}{C{0.15cm}C{0.15cm}C{0.15cm}C{0.15cm}C{0.15cm}C{0.15cm}C{0.15cm}C{0.15cm}C{0.15cm}C{0.15cm}C{0.15cm}}
       \diagonalarrowdown{} & & \diagonalarrowdown{} & & \diagonalarrowdown{} &  & \diagonalarrowdown{} &  & \diagonalarrowdown{} & &\\
      \end{tabular}\\[-0.3ex]
      \begin{tabular}{|C{0.7cm}|C{0.7cm}|C{0.7cm}|C{0.7cm}|C{0.7cm}|}
        \hline
        $c_{0}$ & $c_1$ & $c_2$ & $\cdots$ & $c_{m-1}$\\
        \hline
      \end{tabular}
    \end{tabular}
  \end{minipage}
}
\noindent\fcolorbox{white}{LightSteelBlue}{%
  \begin{minipage}{0.47\textwidth}
    \centering
    \footnotesize
    \begin{tabular}{c}
      \begin{tabular}{|C{0.7cm}|C{0.7cm}|C{0.7cm}|C{0.7cm}|C{0.7cm}|}
        \hline
        $r_0$ & $r_1$ & $r_2$ & $\cdots$ & $r_{m-1}$\\ 
        \hline
      \end{tabular}\\
      \begin{tabular}{C{0.7cm}C{0.7cm}C{0.7cm}C{0.7cm}C{0.7cm}}
        $\lambda$ & $\lambda$ & $\lambda$ & & $\lambda$\\ 
      \end{tabular}\\
      \begin{tabular}{|C{0.7cm}|C{0.7cm}|C{0.7cm}|C{0.7cm}|C{0.7cm}|}
        \hline
        $c_0$ & $c_1$ & $c_2$ & $\cdots$ & $c_{m-1}$\\
        \hline
      \end{tabular}\\
      \begin{tabular}{C{0.7cm}C{0.7cm}C{0.8cm}C{0.7cm}C{0.7cm}}
        $=$ & $=$ & $=$ &  & $=$  
      \end{tabular}\\
      \begin{tabular}{|C{0.7cm}|C{0.7cm}|C{0.7cm}|C{0.7cm}|C{0.7cm}|}
        \hline
        $w_{0}$ & $w_1$ & $w_2$ & $\cdots$ & $w_{m-1}$\\
        \hline
      \end{tabular}\\
    \end{tabular}
  \end{minipage}
  }
  \caption{Pseudo-code and illustration of parallel addition algorithm.}
  \label{fig:addpar}
\end{figure}

The task at hand is to figure out what $\oplus$, $\otimes$ and \texttt{e} is. In the former
work, Olesen et al. found $\oplus$ to compute whether the addition overflows or is
the maximum representable integer as a pair of boolean values s.t. for digits
$x$ and $y$ represented as unsigned integers in base $B$ with wrapping on
overflow, we define:
\begin{equation}
\label{eq:oplus}
x \oplus y \coloneq \tup{x + y < x}{x + y = B-1}
\end{equation}

The operator $\otimes$ then computes the prefix sum on the augmented carries s.t. if
both the addition itself and the one just before it results in the maximum
integer, then they remain the maximum integer combined, and overflows are
determined by the aforementioned conditions. For some pairs of booleans
$x = \tup{\mathit{ov_x}}{\mathit{mx_{x}}}$ and
$y = \tup{\mathit{ov_y}}{\mathit{mx_{y}}}$, we define:
\begin{equation}
  \label{eq:otimes}
  x \otimes y \coloneq \tup{\mathit{ov_x} \land \mathit{mx_y} \lor \mathit{ov_y}}{\mathit{mx_x} \land \mathit{mx_y}}
\end{equation}

They found that the neutral element, \texttt{e}, of $\otimes$ is:
\begin{equation}
  \label{eq:otimesne}
  \mathtt{e} \coloneq \tup{\mathtt{False}}{\mathtt{True}}
\end{equation}

While this approach is intuitive and straightforward to implement, hardware does
not support boolean values natively - they are syntactic sugar for
zero-and-nonzero integer words. Thus, a low-level implementation will have to
use integers, and so we might as well use bitwise operations over logical ones, as
these are faster.

In turn, instead of using pairs of integer words with only one indicator bit for
boolean values each, we combine them to one word with two bits used to each
indicate both boolean value. Not only does this halve the memory usage
w.r.t. the prefix sum, it also increases memory utilization as each workthread
only having to fetch and write one word.

The formalization of these optimizations, where the least and second least
significant bit indicates integer overflow and maximum representable integer,
respectively, is:
\begin{align}
  \label{eq:oplusopt}
  x \oplus y &\coloneq (x + y < x)~|~((x + y = B-1) \ll 1) \\
  \label{eq:otimesopt}
  x \otimes y &\coloneq (((x~\&~(y \gg 1))~|~y)~\&~1)~|~(x~\&~y~\&~2)\\
  \label{eq:otimesneopt}
  \mathtt{e} &\coloneq 2
\end{align}

Equation (\ref{eq:oplusopt}) is a straightforward conversion of equation
(\ref{eq:oplus}), with the pair being replaced by the shift- and bitwise or-operator.

Equation (\ref{eq:otimesopt}) is a conversion of equation (\ref{eq:otimes}),
where I) the pair is replaced with bitwise or-operator, II) the first clause is checked
in the least significant bit and zeroes out the second bit with ``$\&~1$'', and
III) the second clause is checked in the second least significant bit and zeroes
out the first bit with ``$\&~2$''. Associtivity naturally still holds:

\begin{proof}
  We want to show $x \otimes (y \otimes z) = (x \otimes y) \otimes z$. From left-to-right we have:
\begin{align}
  (x \otimes y) \otimes z &= (~\underbrace{(((x~\&~(y \gg 1))~|~y)~\&~1)~|~(x~\&~y~\&~2)}_{\alpha}~) \otimes z\\
              &= (((\alpha~\&~(z \gg 1))~|~z)~\&~1)~|~(\alpha~\&~z~\&~2)\\
              \label{eq:otimesproofltr}
              &= (((\alpha~\&~1)~\&~(z \gg 1))~|~(z~\&~1))~|~((\alpha~\&~2)~\&~z)
\end{align}
From right-to-left we have:
\begin{align}
  x \otimes (y \otimes z) &= x \otimes (~\underbrace{((y~\&~(z \gg 1))~|~z)~\&~1)~|~(y~\&~z~\&~2)}_{\beta}~)\\
  &= (((x~\&~(\beta \gg 1))~|~\beta)~\&~1)~|~(x~\&~\beta~\&~2)\\
  \label{eq:otimesproofrtl}
  &= ((x~\&~(\beta \gg 1)~\&~1)~|~(\beta~\&~1))~|~(x~\&~(\beta~\&~2))
\end{align}
We must now show that equation (\ref{eq:otimesproofltr}) is equal to
(\ref{eq:otimesproofrtl}). Consider the second clause. Since $(1~\&~2)$ is $0$,
so is the first clause of both $(\alpha~\&~2)$ and $(\beta~\&~2)$. Futhermore, we have
that $2~\&~2$ is the same as $2$. Thus, we have:
\begin{align}
  (\alpha~\&~2)~\&~z &= (x~\&~y~\&~2)~\&~z\\
                &= x~\&~(y~\&~z~\&~2)\\
                &= x~\&~(\beta~\&~2)
\end{align}
Consider the first clause. Again, $(2~\&~1)$ is $0$, so the second clause of $(\alpha~\&~1)$ is $0$:
\begin{align}
  ((\alpha~\&~1)~\&~&(z \gg 1))~|~(z~\&~1) \\
               &= ((((x~\&~(y \gg 1))~|~y)~\&~1)~\&~(z \gg 1))~|~(z~\&~1) \\
               &= (((x~\&~(y \gg 1)~\&~1)~|~(y~\&~1))~\&~(z \gg 1))~|~(z~\&~1) \\
               &= ((x~\&~(y \gg 1)~\&~(z \gg 1)~\&~1)~|~(y~\&~(z \gg 1)~\&~1))~|~(z~\&~1)
\end{align}
We have $((y \gg 1)~\&~(z \gg 1)) = (y~\&~z \gg 1) = (y~\&~z~\&~2 \gg 1)$ and get:
\begin{align}
  &= (x~\&~((y~\&~z~\&~2) \gg 1)~\&~1)~|~(y~\&~(z \gg 1)~\&~1)~|~(z~\&~1))\\
  \phantom{((\alpha~\&~1)\&}&= (x~\&~((y~\&~z~\&~2) \gg 1)~\&~1)~|~((y~\&~(z \gg 1))~|~z)~\&~1)\\
  &= (x~\&~(\beta \gg 1)~\&~1)~|~(\beta~\&~1)
\end{align}
Thus, equations (\ref{eq:otimesproofltr}) and (\ref{eq:otimesproofrtl}) are equal, and hence, $x \otimes (y \otimes z) = (x \otimes y) \otimes z$.
\end{proof}

Likewise, the netrual element \texttt{e} of Equation (\ref{eq:otimesneopt}) is
the corresponding indicator bits of Equation (\ref{eq:otimesne}), and so
\texttt{e} remains a left-associative neutral element of $\otimes$ after the
optimizations:

\begin{proof} By exhaustive evaluation we have:
\begin{align}
  \label{eq:otimesneproof}
  2 \otimes 0 &= (((2~\&~(0 \gg 1))~|~0)~\&~1)~|~(2~\&~0~\&~2) = 0 \\
  2 \otimes 1 &= (((2~\&~(1 \gg 1))~|~1)~\&~1)~|~(2~\&~1~\&~2) = 1 \\
  2 \otimes 2 &= (((2~\&~(2 \gg 1))~|~2)~\&~1)~|~(2~\&~2~\&~2) = 2 \\
  2 \otimes 3 &= (((2~\&~(3 \gg 1))~|~3)~\&~1)~|~(2~\&~3~\&~2) = 3
\end{align}
\end{proof}

Thus, when using the parallel algorithm presented in Figure \ref{fig:addpar}
with $\oplus$, $\otimes$ and \texttt{e} defined in Equations (\ref{eq:oplus}),
(\ref{eq:otimesne}) and (\ref{eq:otimesneopt}), we get that
$\mathtt{f} \coloneq 1~\&$. Both $\oplus$, $\otimes$ and \texttt{f} are $O(1)$, and so the
\fun{map}s exhibit work $O(m)$ and span $O(1)$, and the \fun{scan} work $O(m)$
and span $O(\log m)$. Thus, the work of a parallel big integer addition is
$O(m)$ and the span is $O(\log m)$.


\subsection{CUDA Implementation}
\label{subsec:addcud}

{\color{red} TODO write about further optimizitations, e.g. upping the sequentialization factor}

\subsection{Futhark Implementation}
\label{subsec:addfut}

%%% Local Variables:
%%% mode: LaTeX
%%% TeX-master: "../main"
%%% End:
